{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valuable-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authors: Leo Hu and Natnael Mulat\n",
    "# Package imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "piano-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497\n",
      "4547\n"
     ]
    }
   ],
   "source": [
    "#import red and white wines data separately\n",
    "red = pd.read_csv(\"winequality-red.csv\", sep=';')\n",
    "white = pd.read_csv(\"winequality-white.csv\", sep=';') \n",
    "\n",
    "red[\"type\"] = np.ones(len(red[\"fixed acidity\"]),dtype='int64')#assigning 1 to red wines\n",
    "white[\"type\"] = np.zeros(len(white[\"fixed acidity\"]),dtype='int64')#assigning 0 to white wines\n",
    "data = pd.concat([red, white])\n",
    "print(len(data))\n",
    "#Data_train, Data_test = train_test_split(data, test_size=0.30, random_state=40, shuffle=True)#spliting data into train and test(70-30)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[list(set(list(data.columns))-set(['quality']))], data[\"quality\"], test_size=0.3, random_state=123, shuffle=True)\n",
    "#standardize Data_train\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "cols = list(set(list(X_train.columns))-set(['type']))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[cols])\n",
    "X_train[cols] = scaler.transform(X_train[cols])\n",
    "X_test[cols] = scaler.transform(X_test[cols])\n",
    "n = len(X_train)\n",
    "print(n)\n",
    "p = len(X_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tired-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4585440950076974\n",
      "MSE:0.532387724996054, R2: 0.2972488705695454, Adjusted_R2: 0.29538892051370835\n"
     ]
    }
   ],
   "source": [
    "linear_regress = LinearRegression()\n",
    "#linear_regress.fit(X_train,y_train)\n",
    "y_pred = cross_val_predict(linear_regress, X_train, y_train, cv=10)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "living-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge-regression with degree-2 polynomial\n",
    "# leave-one-out cross validation to chose an lamda\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6,6, 13))\n",
    "reg.fit(X_poly,y_train)\n",
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "portuguese-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45260611392126676\n",
      "MSE:0.5078310436597502, R2: 0.3296636591416884, Adjusted_R2: 0.31612454992327543\n"
     ]
    }
   ],
   "source": [
    "# ridge-regression with degree-1 polynomial\n",
    "# with the chosen hyperparameter lamda\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Ridge(lamda)\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=10)\n",
    "\n",
    "n = len(X_poly)\n",
    "p = len(X_poly[1])\n",
    "accuracy = accuracy_score(y_train.astype(int), y_pred.astype(int))\n",
    "print(accuracy)\n",
    "\n",
    "#loo = LeaveOneOut()\n",
    "#scores = cross_val_score(reg, X_train, y_train, scoring='neg_mean_squared_error', cv=loo)\n",
    "#print(np.mean(scores))\n",
    "#y_pred = reg.predict(X_poly)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exciting-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n",
      "0.42577523641961734\n",
      "MSE:0.5668558130791611, R2: 0.2517510375195977, Adjusted_R2: 0.16873416827079457\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "reg.fit(X_poly,y_train)\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Ridge(lamda)\n",
    "#reg.fit(X_poly,y_train)\n",
    "\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=10)\n",
    "\n",
    "n = len(X_poly)\n",
    "\n",
    "p = len(X_poly[1])\n",
    "\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gothic-mainland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1819\n",
      "0.35451946338244994\n",
      "MSE:1.2995128603737647, R2: -0.7153553462259721, Adjusted_R2: -1.8595546035728892\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=4, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "reg.fit(X_poly,y_train)\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Ridge(lamda)\n",
    "#reg.fit(X_poly,y_train)\n",
    "#y_pred = reg.predict(X_poly)\n",
    "#cv = LeaveOneOut()\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=10)\n",
    "\n",
    "n = len(X_poly)\n",
    "\n",
    "p = len(X_poly[1])\n",
    "print(p)\n",
    "\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "invisible-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3707939300637783\n",
      "MSE:3.16382550598828, R2: -3.176245700763711, Adjusted_R2: -3.187298843333001\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=5, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "reg.fit(X_poly,y_train)\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Ridge(lamda)\n",
    "#reg.fit(X_poly,y_train)\n",
    "#y_pred = reg.predict(X_poly)\n",
    "#cv = LeaveOneOut()\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=10)\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ignored-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 416.78354835594104, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 804.0872265882872, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 843.6418710274221, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8507051556300667, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 575.1024955844441, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 768.1088232221277, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 229.85331367472122, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 786.6153338892631, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 841.3161759106621, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 647.1026013235181, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 816.8839314393556, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 837.8120529427194, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.009366655533995, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 625.1538494219412, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 809.690680581536, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45370574004838354\n",
      "MSE:0.513780329244301, R2: 0.32181060962992813, Adjusted_R2: 0.3200156663823672\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.LassoCV(alphas=np.logspace(-6,6,13))\n",
    "reg.fit(X_poly,y_train)\n",
    "lamda=reg.alpha_\n",
    "\n",
    "reg = linear_model.Lasso(lamda, tol=0.001)\n",
    "\n",
    "#reg.fit(X_poly,y_train)\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=10)\n",
    "\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "\n",
    "#y_pred = reg.predict(X_poly)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "approximate-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4589839454585441\n",
      "MSE:0.5322800802873865, R2: 0.2973909614500101, Adjusted_R2: 0.29553138746178775\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.LassoCV(alphas=np.logspace(-5,5,13))\n",
    "reg.fit(X_train,y_train)\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Lasso(lamda)\n",
    "#reg.fit(X_poly,y_train)\n",
    "#cv_mse = np.mean(reg.cv_values_,axis=0)\n",
    "#cv = LeaveOneOut()\n",
    "y_pred = cross_val_predict(reg, X_train, y_train, cv=10)\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "\n",
    "#y_pred = reg.predict(X_poly)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dangerous-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4765779634924126\n",
      "MSE:0.8500109962612712, R2: -0.12201344923071189, Adjusted_R2: -0.12498304812589689\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.SGDClassifier(max_iter = 10000, tol=1e-3)\n",
    "y_pred = cross_val_predict(reg, X_train, y_train, cv=3)\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))#R2 is considered to be weak or has no effect since it is lower than 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eleven-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 355.90497949390374, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 811.1719724822107, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 844.793021986235, tolerance: 0.2784027495188347\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.744894898087523, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 468.0055683704418, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 721.7430384379181, tolerance: 0.27569084410228184\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156.11015429929898, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 798.3236298928935, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 843.2527139740833, tolerance: 0.27556965365585484\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 639.2884732211048, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 821.0817447372071, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 838.4323629089979, tolerance: 0.2746644584936778\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7821077936555412, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6275926059543053, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 720.4205095010757, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n",
      "/opt/conda/envs/common/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:528: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 821.6102478016976, tolerance: 0.2735352666300161\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.458324169782274\n",
      "MSE:0.5344159043057456, R2: 0.29457167642389936, Adjusted_R2: 0.29270464071968383\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "reg = linear_model.LassoCV(alphas=np.logspace(-6,6,13))\n",
    "reg.fit(X_train,y_train)\n",
    "lamda=reg.alpha_\n",
    "\n",
    "reg = linear_model.SGDClassifier(max_iter = 1000000, tol=1e-3, penalty='l1', alpha = lamda, learning_rate = 'adaptive',eta0 = 0.0001)\n",
    "reg.fit(X_poly, y_train)\n",
    "y_pred = cross_val_predict(reg, X_poly, y_train, cv=3)\n",
    "\n",
    "MSE=mean_squared_error(y_train, y_pred)\n",
    "R2=r2_score(y_train, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "accuracy = accuracy_score(y_pred.astype(int), y_train.astype(int))\n",
    "print(accuracy)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "familiar-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44153846153846155\n",
      "MSE:0.5301639379892396, R2: 0.3145319965671036, Adjusted_R2: 0.2384805611911175\n"
     ]
    }
   ],
   "source": [
    "# ridge-regression with degree-2 polynomial\n",
    "# leave-one-out cross validation to chose an lamda\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_test)\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-6,6, 13))\n",
    "reg.fit(X_poly,y_test)\n",
    "reg.alpha_\n",
    "lamda=reg.alpha_\n",
    "reg = linear_model.Ridge(lamda)\n",
    "y_pred = cross_val_predict(reg, X_poly, y_test, cv=10)\n",
    "accuracy = accuracy_score(y_test.astype(int), y_pred.astype(int))\n",
    "print(accuracy)\n",
    "\n",
    "#loo = LeaveOneOut()\n",
    "#scores = cross_val_score(reg, X_train, y_train, scoring='neg_mean_squared_error', cv=loo)\n",
    "#print(np.mean(scores))\n",
    "#y_pred = reg.predict(X_poly)\n",
    "MSE=mean_squared_error(y_test, y_pred)\n",
    "R2=r2_score(y_test, y_pred)\n",
    "adjusted_R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('MSE:'+str(MSE)+', R2: '+str(R2)+', Adjusted_R2: '+str(adjusted_R2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
